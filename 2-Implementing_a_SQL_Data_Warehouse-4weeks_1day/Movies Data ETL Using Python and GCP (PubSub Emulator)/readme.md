# ğŸ¥ ETL Movies Data Project

## **ğŸš€ Project Overview**

Welcome to the ETL Movies Data Project! ğŸŒŸ This project is a deep dive into building an end-to-end ETL (Extract, Transform, Load) pipeline using Python, Docker, and a Google Cloud Pub/Sub emulator. Weâ€™re working with a dataset of movie ratings, transforming it into a format that's ready for analysis, and loading it into a Docker container for easy access and management. This project is perfect for those looking to simulate a real-world ETL process in a local environment. ğŸ’»

---

## **ğŸ—‚ Project Structure**

Hereâ€™s how our project is organized:

### `ETL_MOVIES/`
- **`data/`**                           # Where all the magic data lives! ğŸ©
  - **`ratings.csv`**                 # Contains rated movie data ğŸ“Š
  - **`movies.csv`**                  # Contains information about movies ğŸ¥
  - **`full_data.csv`**               # The preprocessed movie data file ğŸ—ƒ

- **`Dockerfile`**                    # Our recipe for the Docker environment ğŸ“¦

- **`requirements.txt`**              # All the ingredients (dependencies) ğŸ› 

- **`README.md`**                     # This very guide youâ€™re reading! ğŸ“š

- **`Scripts/`**                      # Scripts to automate various tasks ğŸ›
  - **`setup_env.bat`**               # Environment setup script âš™ï¸
  - **`download_data.bat`**           # Data download script â¬‡ï¸
  - **`start_emulator.py`**           # Start the Pub/Sub emulator ğŸš€
  - **`create_topic_subscription.py`** # Create Pub/Sub topic and subscription ğŸ“
  - **`publish_test_message.py`**     # Test data ingestion ğŸ§ª
  - **`process_data.py`**             # Extract CSV files ğŸ“‚
  - **`preprocessing_data.py`**       # Clean up the data ğŸ§¼
  - **`publish_data.py`**             # Publish data to the container ğŸšš

Feel free to explore each part of the project to understand its role and how everything fits together. Happy coding! ğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’»


## **ğŸ”§ Tools and Technologies**

- **Python** ğŸ: The core language for our scripts.
- **Docker** ğŸ³: To containerize and run everything smoothly.
- **Google Cloud Pub/Sub** â˜ï¸: For simulating real-time data streaming.
- **Pandas** ğŸ¼: Our go-to for data manipulation.
- **Windows Batch Scripting** ğŸ–¥: Automating the setup and downloads.
- **Google Cloud SDK** ğŸŒ: For interacting with Google Cloud services.

---

## **ğŸ“‹ Environment Setup**

Ready to get started? Hereâ€™s what you need to do:

1. **Install Required Tools:**
   - Docker Desktop
   - Python 3.x
   - Google Cloud SDK

2. **Clone the Repository:**
   - Use Git to clone the repository and dive into the project directory.

3. **Install Python Dependencies:**
   - Create a virtual environment and install dependencies with a flick of a command.

---

## **ğŸ“š Project Steps**

Hereâ€™s a step-by-step guide to get you through the project:

### **1ï¸âƒ£ Setup Environment**

**Goal:** Set up the project environment with all the necessary dependencies.

**How:** Run the `setup_env.bat` script, and let the automation magic happen! âœ¨

---

### **2ï¸âƒ£ Download Data**

**Goal:** Get the movie ratings data.

**How:** Simply run `download_data.bat`, and the data will be at your service! ğŸ“¥

---

### **3ï¸âƒ£ Set Up Pub/Sub Emulator**

**Goal:** Simulate the Pub/Sub environment locally.

**How:** Kickstart the emulator with `start_emulator.py`. ğŸš€

---

### **4ï¸âƒ£ Build Docker Image**

**Goal:** Package everything into a Docker image.

**How:** Build the image using Docker, and watch it come to life! ğŸ› 

---

### **5ï¸âƒ£ Run Docker Container**

**Goal:** Spin up the Docker container.

**How:** Use the Docker run command, and let the container do its thing. ğŸƒâ€â™‚ï¸

---

### **6ï¸âƒ£ Create Pub/Sub Topic and Subscription**

**Goal:** Create a Pub/Sub topic and subscription.

**How:** Execute `create_topic_subscription.py`, and set the stage for data flow. ğŸŒ

---

### **7ï¸âƒ£ Test Data Ingestion**

**Goal:** Ensure data ingestion works smoothly.

**How:** Run `publish_test_message.py` and see the messages flow! ğŸ¯

---

### **8ï¸âƒ£ Extract CSV Files**

**Goal:** Extract and prepare the data.

**How:** Run `process_data.py` and get your CSVs ready for action! ğŸ“‘

---

### **9ï¸âƒ£ Preprocess Data**

**Goal:** Clean and prep the data.

**How:** Execute `preprocessing_data.py`, and your data will be spotless! ğŸ§¼
- inside this Python file:
  - null values have been filled
  - datatype correction
  - merge data depending on the item_id

---

### **ğŸ”Ÿ Create Folder in Docker Container**

**Goal:** Create a place in the container for our data.

**How:** Access the Docker terminal and create the `/data` folder. ğŸ“‚

---

### **1ï¸âƒ£1ï¸âƒ£ Publish Data to Container**

**Goal:** Send the data into the Docker container.

**How:** Run `publish_data.py` and watch the data transfer! ğŸšš

---

## **ğŸ’¡ Understanding Pub/Sub and Its Role**

Google Cloud Pub/Sub is all about handling data in real-time, and this project, allows us to simulate how large-scale data processing would work in the cloud. The Pub/Sub emulator lets us develop and test everything locally, so weâ€™re ready for the real cloud when the time comes. â˜ï¸

---

## **ğŸš§ Challenges Faced**

- **Handling Big Data:** Processing 100,000 rows was a challenge, but we conquered it! ğŸ’ª
- **Local Cloud Simulation:** Setting up the Pub/Sub emulator wasnâ€™t easy, but it was worth it. ğŸ“
- **Data Cleaning:** Ensuring clean and reliable data required some serious attention to detail. ğŸ§¹

---

## ** â­ Result**

![image](https://github.com/user-attachments/assets/736f8cd2-bab3-4306-8e24-a3d266961f41)


---

## **ğŸ‰ Conclusion**

This project is a full demonstration of how to build a robust ETL pipeline, complete with Dockerization and cloud simulations. Whether youâ€™re here to learn or to build, this project has all the tools and guidance you need. Happy coding! ğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’»



---

## **ğŸ“‚ Repository**

Find everything you need in our [GitHub repository](https://github.com/nadahamdy217/Movies-Data-ETL-using-Python-GCP/tree/main). Dive in, explore, and feel free to contribute! ğŸ

---

## **Contributing**

We welcome contributions to this project! If youâ€™d like to contribute or have any questions, please contact:

- **Author:** [Nada Hamdy Fatehy]
- **Email:** nadahamdy2172002@gmail.com
- **LinkedIn:** [LinkedIn](https://www.linkedin.com/in/nada-hamdy-2265692a3/)
- **GitHub:** [GitHub](https://github.com/nadahamdy217)


